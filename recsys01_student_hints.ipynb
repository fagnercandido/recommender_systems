{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9731ea-94b4-4e66-bd85-08227ecbe600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reserved for package imports\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f644719e-ad96-40e7-9176-01b44c479055",
   "metadata": {},
   "source": [
    "# Recommender systems:\n",
    "## Long tutorial Part I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2585e7bf-b662-4099-84c9-1cbb53b3c670",
   "metadata": {},
   "source": [
    "The goal of this long tutorial is that you explore how to use data from users in the context of recoomendation systems. During the lecture you learn that user data on some online content product or service can have two forms: implicit and explicit.\n",
    "\n",
    "In this long tutorial you will work with some datasets on books and user ratings on those books. Make sure you have access to the three `.csv` files for this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04e9050-3c48-416b-a475-5e56ca2de722",
   "metadata": {},
   "source": [
    "### 1. Ensure path to source data\n",
    "First of all, ensure that your Jupyter pointer to current working diretory can access the `.csv` files. The code below applies to my directory system, you must replace this with your own path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9313847a-0d37-439e-9d0c-39640d23a919",
   "metadata": {},
   "outputs": [],
   "source": [
    "## replace xxxxx as appropriate\n",
    "os.chdir(' xxxxx ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990d59f9-d602-4d03-945b-2de52ce9bd0e",
   "metadata": {},
   "source": [
    "### 2. Load the csv files as Pandas dataframes\n",
    "\n",
    "Remember to add your required imports in the top cell of this notebook. Import `Pandas` as `pd`. Also, use the option `low_memory=False` when loading your dataframes (this is because our files are relatively large. Do not set the index to anything. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfb2564-e5b7-41f9-9b9b-45032b8d30b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add your code to load the csv as pandas dataframes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c446e688-1f49-4918-8eaa-0324eaf21caa",
   "metadata": {},
   "source": [
    "### 3. Have a quick look at the content of your dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e16c3b-c640-4e1d-8db7-b31b86d0171f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30320b9c-9b1d-4a24-8d76-815858af3338",
   "metadata": {},
   "source": [
    "### 4. Describing content and relationships\n",
    "\n",
    "Describe in this cell the content of each dataframe, and determine whether the attributes in them establish relationships between the dataframes. More specifically, what entities are represented? what attributes of each? What are the data types for each atribute? Is there any entity that acts as a connector between others? Explain.\n",
    "\n",
    "|  Your answer here  \n",
    "|  \n",
    "|  \n",
    "|  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad9d556-b635-48fe-a7df-6812cd1ced26",
   "metadata": {},
   "source": [
    "### 5. How many people read each book in the dataset?\n",
    "\n",
    "Notice that the ratings dataframe relates each user with all the books they have read through a rating from zero to ten. If there is no rating, then it means the person did not read the book. Using this information, create a dataframe that is indexed by ISBN, and contains a column that represents the number of people who have read each book "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ed3421-1319-492f-8990-132a420dd7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add your code here, hint: pandas groupby may be useful\n",
    "## also you may want to restrict your dataset to a portion of the data for testing your code\n",
    "\n",
    "## Hint: here you may consider using the Pandas groupby functionality applied to the slide of\n",
    "## the ratings dataframe that contains User-ID and ISBN. You want to group by ISBN and to the \n",
    "## result apply the function count, so that the result is a dataframe that contains the number\n",
    "## of readers per ISBN. There are other solutions to this problem. You want to avoid using \n",
    "## for loops.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c732f3a-611a-4071-8606-270b63b8279b",
   "metadata": {},
   "source": [
    "### 6. What are the top five most read books?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87945bf-17f8-4266-ba5d-fa3eee0141cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add your code here, use Pandas utilities\n",
    "\n",
    "## Hint: for this question you may want to visit the sort_values function in Pandas and apply it to the\n",
    "## result you obtained in Question 5. Make sure the ordering is not ascending. Then you want to take the \n",
    "## top five ISBNs and get their information from the books dataframe leveraring the isin Pandas function.\n",
    "## There are other possible solutions. Avoid for loops."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c60e07-b1b8-4fdc-bc8a-a53e4e0d0ecf",
   "metadata": {},
   "source": [
    "### 7. What proportion (%) of people read more than five books? 20 books?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4a4774-8f04-48ae-bfcd-4ede213d2b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add your code here\n",
    "\n",
    "## Hint. Get this information from the result of Q5 by slicing on the ISBNs with more than 5\n",
    "## or 20 books, compute proportion and express as percentage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c08589-cc24-4fdb-b24f-36aa015386ce",
   "metadata": {},
   "source": [
    "### 8. Obtaining a reduced dataset for code experiments\n",
    "\n",
    "Create a dataframe, `reduced_ratings_df` that contains the the `User-ID` `ISBN` and `Book-Rating` for all the books that have been read by `n` people or more. When `n=250` check in the resulting dataframe that you have information about 124 books, read by 18512 users and where there are 49408 user-book ratings (rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbd9734-8f86-4de3-bb3d-e03d1b3b3539",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add your code here, try n=250 and n=500\n",
    "\n",
    "## Hint. Here, once again you want to use the dataframe you computed in Q5,\n",
    "## the the slice of books (ISBN) with more than 250 (or 500) readers. \n",
    "## Use the ISBNs in this slice along with the function isin to get the ratings info\n",
    "## for these books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c526f18-3742-419b-a5aa-579744e2e17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Confirm that the number of books is 124\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e472d6-79ae-4dbb-9adc-6f9f104b7e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Confirm that the number of users is 18512\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede988d8-7a1f-4437-b695-dc88b2f2aac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## See how many total user x book entries exist in the new dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fe0c84-badd-4c1a-8de7-d0ba3eeea1f8",
   "metadata": {},
   "source": [
    "#### 8.1 Do we need to create reduced dataframes for the original users and books?\n",
    "\n",
    "|  Your answer here  \n",
    "|  \n",
    "|  \n",
    "|  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a540114b-b95a-4e62-b1b7-7c10b8c41d8d",
   "metadata": {},
   "source": [
    "### 9. Creating a rectangular matrix for implicit user data\n",
    "\n",
    "The goal of this task is to create a rectangular data structure were rows are books, and columns are users. The value of a matrix cell, for book `i` and user `j`, is one if the user has read the book (we do not care about the ratings at this point) and zero is `j` has not read book `i`. Since we know the original dataset is large, your code must be able to produce this matrix in reasonable time. Test it first on the reduced dataset you created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c980b51-74ae-4f9d-8569-4ee94311dc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## First of all, I want the row and column names\n",
    "\n",
    "## Hint 1: create a variable \"books\" that is a sorted numpy array of the unique ISBNs in the ratings dataframe created in Q8\n",
    "## Hint 2: create a variable \"users\" that is a sorted numpy array of the unique User-ID in the ratings dataframe created in Q8\n",
    "\n",
    "## Second, I create single argument dummy functions to get the index of a book or user\n",
    "\n",
    "## Hint 3: in these functions, you want to pass either a ISBN (User-ID), and use the numpy function where\n",
    "## to get back the index of that ISBN (User-ID) from the books (users) variables you created above.\n",
    "## Be careful with the output of numpy where, make sure you fetch the integer index only\n",
    "\n",
    "## Third, I get the pairs of indexes for books and users in the reduced dataframe\n",
    "## these are the pairs for which users rated books, which means they read them\n",
    "\n",
    "## Hint 4: here you can use the map function to apply the functions you just created to the corresponding \n",
    "## columns of the reduced ratings you created in Q8. Call the books indexes bindex and the users indexes uindex\n",
    "\n",
    "\n",
    "## Hint 5: Finally, I create a numpy all zeros matrix and reshape it so that\n",
    "## it has number of rows = number of unique books and \n",
    "## number of columns = number of unique users.\n",
    "## Then I use numpy multiple assignment to assign the value one to \n",
    "## all possible pairs (book, user) in the matrix I have just created\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a69bd1-2441-48ff-9215-ff2093c0407a",
   "metadata": {},
   "source": [
    "### 10. Compute the cosine similarity matrix of readers\n",
    "\n",
    "Use your own `cosine_similarity` function or import it from `sklearn.metrics.pairwise` to compute a cosine similatity matrix for all the users in the reduced dataframe. The size of this matrix should be number-of-users x number-of-users, it should be a diagonal, symmetric matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7d6434-9e6c-4f07-b596-0a5dea0c665b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16a135b-8f58-4819-bad8-4c224847616b",
   "metadata": {},
   "source": [
    "### 11. Mainstream and alternative readers\n",
    "\n",
    "Using a simple, analytical, approach explore the cosine similarity matrix you just obtained to determine whether there are groups of users we could call more \"mainstream\" because there are many users who read the same books, and others we would call \"alternative\" who don't share many similarities with other users. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5ca2e5-7958-4b25-8cb9-606403957d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add your code here to process the similarity matrix in a way \n",
    "## that you can use it to infer mainstream and alternative users\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf0cd71-898c-4cc8-a74e-20c7e4ba00a0",
   "metadata": {},
   "source": [
    "#### 11.1 What is the location of the most mainstream user?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5564368-1fde-43d8-afc9-e2667f0a7f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d15cbbc-df08-4d9e-897e-609661063800",
   "metadata": {},
   "source": [
    "#### 11.2 How many users are most alternative?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9019dce5-cabb-4458-8098-d3a04464a411",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095a1bcd-f4e9-4bfb-94b4-1fa3b3cc1e81",
   "metadata": {},
   "source": [
    "### 12. (Think) How can we think about recommendations based on what others have read?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2d22eb-6c6c-4f82-a8a2-f0ab4d9a3bf9",
   "metadata": {},
   "source": [
    "### 13. (Think) What happens when we change the informtion source to ratings instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a80126-e8e8-4d59-be32-ead874a44044",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "355a6f18c4c1ce720903482e4d677f8b73f074d671ed62dac27f896597ea65a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
